{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab6/Laborator_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3a1x3D2pJlE"
      },
      "source": [
        "# Învățare Automată\n",
        "# Învățare prin Recompensă - rezolvarea proceselor de decizie Markov prin tehnici de programare dinamică (Value Iteration, Policy Iteration)\n",
        "### Autori:\n",
        "* Tudor Berariu - 2018\n",
        "* Alexandru Sorici - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6-C84FKpUfB"
      },
      "source": [
        "## 1. Scopul laboratorului"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTKbkxAwpYhl"
      },
      "source": [
        "Scopul laboratorului îl reprezintă înțelegerea conceptelor de proces markov de decizie (MDP), politică, valoare de stare, precum și implementarea unor metode de programare dinamică pentru rezolvarea problemei de control a unui MDP.\n",
        "\n",
        "În cadrul laboratorului veți:\n",
        "- implementa algoritmul de iterare a politicilor\n",
        "- implementa algoritmul de iterare a valorilor de stare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i_6oVDI-zp5"
      },
      "source": [
        "## 2. Workspace setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTs6cwy5_Na7"
      },
      "source": [
        "### Câteva bibioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Y6WMfQ_R5L"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os.path\n",
        "from argparse import ArgumentParser\n",
        "from copy import copy\n",
        "from random import choice\n",
        "\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMSc8oHEdLK"
      },
      "source": [
        "### Definirea unui labirint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09ToJHh-Ef2S"
      },
      "outputs": [],
      "source": [
        "class Maze:\n",
        "\n",
        "    NORTH, EAST, SOUTH, WEST = 0, 1, 2, 3  # actions\n",
        "\n",
        "    DYNAMICS = {  # the stochastic effects of actions\n",
        "        NORTH: {(0, -1): 0.1, (-1, 0): .8, (0, 1): .1},\n",
        "        EAST: {(-1, 0): 0.1, (0, 1): .8, (1, 0): .1},\n",
        "        SOUTH: {(0, 1): 0.1, (1, 0): .8, (0, -1): .1},\n",
        "        WEST: {(1, 0): 0.1, (0, -1): .8, (-1, 0): .1},\n",
        "    }\n",
        "\n",
        "    WALL, EMPTY = \"x\", \" \"\n",
        "\n",
        "    VISUALS = {\n",
        "        (0, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND RIGHT}\",\n",
        "        (1, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND LEFT}\",\n",
        "        (1, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY HORIZONTAL}\",\n",
        "        (0, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND RIGHT}\",\n",
        "        (1, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP AND LEFT}\",\n",
        "        (0, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL}\",\n",
        "        (1, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        (1, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND HORIZONTAL}\",\n",
        "        (1, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND LEFT}\",\n",
        "        (1, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND HORIZONTAL}\",\n",
        "        (0, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND RIGHT}\",\n",
        "        (1, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY LEFT}\",\n",
        "        (0, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP}\",\n",
        "        (0, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY RIGHT}\",\n",
        "        (0, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN}\",\n",
        "        (0, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        WEST: \"\\N{LEFTWARDS ARROW}\",\n",
        "        NORTH: \"\\N{UPWARDS ARROW}\",\n",
        "        EAST: \"\\N{RIGHTWARDS ARROW}\",\n",
        "        SOUTH: \"\\N{DOWNWARDS ARROW}\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, map_name):\n",
        "        self._rewards, self._cells = {}, []\n",
        "        with open(os.path.join(\"maps\", map_name), \"r\") as map_file:\n",
        "            for line in map_file.readlines():\n",
        "                if \":\" in line:\n",
        "                    name, value = line.strip().split(\":\")\n",
        "                    self._rewards[name] = float(value)\n",
        "                else:\n",
        "                    self._cells.append(list(line.strip()))\n",
        "        self._states = [(i, j) for i, row in enumerate(self._cells)\n",
        "                        for j, cell in enumerate(row) if cell != Maze.WALL]\n",
        "\n",
        "    @property\n",
        "    def actions(self):\n",
        "        return [Maze.NORTH, Maze.EAST, Maze.SOUTH, Maze.WEST]\n",
        "\n",
        "    @property\n",
        "    def states(self):\n",
        "        return copy(self._states)\n",
        "\n",
        "    def is_final(self, state):\n",
        "        row, col = state\n",
        "        return self._cells[row][col] != Maze.EMPTY\n",
        "\n",
        "    def effects(self, state, action):\n",
        "        if self.is_final(state):\n",
        "            return []\n",
        "        row, col = state\n",
        "        next_states = {}\n",
        "        for (d_row, d_col), prob in Maze.DYNAMICS[action].items():\n",
        "            next_row, next_col = row + d_row, col + d_col\n",
        "            if self._cells[next_row][next_col] == Maze.WALL:\n",
        "                next_row, next_col = row, col\n",
        "            if (next_row, next_col) in next_states:\n",
        "                prev_prob, _ = next_states[(next_row, next_col)]\n",
        "                prob += prev_prob\n",
        "            cell = self._cells[next_row][next_col]\n",
        "            reward = self._rewards[\"default\" if cell == Maze.EMPTY else cell]\n",
        "            next_states[(next_row, next_col)] = (prob, reward)\n",
        "        return [(s, p, r) for s, (p, r) in next_states.items()]\n",
        "\n",
        "    def print_policy(self, policy):\n",
        "        last_row = []\n",
        "        height = len(self._cells)\n",
        "\n",
        "        for row, row_cells in enumerate(self._cells):\n",
        "            width = len(row_cells)\n",
        "            for col, cell in enumerate(row_cells):\n",
        "                if cell == Maze.WALL:\n",
        "                    north, south, west, east = 0, 0, 0, 0\n",
        "                    if last_row and len(last_row) > col:\n",
        "                        north = last_row[col] == Maze.WALL\n",
        "                    if row + 1 < height:\n",
        "                        south = self._cells[row + 1][col] == Maze.WALL\n",
        "                    if col > 0:\n",
        "                        west = row_cells[col - 1] == Maze.WALL\n",
        "                    if col + 1 < width:\n",
        "                        east = row_cells[col + 1] == Maze.WALL\n",
        "                    sys.stdout.write(Maze.VISUALS[(west, north, east, south)])\n",
        "                elif self.is_final((row, col)):\n",
        "                    sys.stdout.write(cell)\n",
        "                else:\n",
        "                    action = policy[(row, col)]\n",
        "                    sys.stdout.write(Maze.VISUALS[action])\n",
        "            sys.stdout.write(\"\\n\")\n",
        "            last_row = row_cells\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    def print_values(self, v):\n",
        "        for r, row_cells in enumerate(self._cells):\n",
        "            print(\" | \".join([\"%5.2f\" % v[(r, c)] if cell == Maze.EMPTY else \"     \"\n",
        "                              for c, cell in enumerate(row_cells)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-G9p2SH-r0V"
      },
      "source": [
        "## Cerințe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJRLjzstZWw3"
      },
      "outputs": [],
      "source": [
        "MAP_NAME = 'simple'  #@param ['simple', 'complex', 'be_careful', 'suffer']\n",
        "gamma = 0.8 #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.1}\n",
        "max_delta = 1e-8 #@param {type:\"float\"}."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg6lghd0ZWw3"
      },
      "source": [
        "### Cerința 1\n",
        "Implementați funcția **policy_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1B6NK3CZWw3"
      },
      "outputs": [],
      "source": [
        "def policy_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    v = {s: 0 for s in game.states}\n",
        "    policy = {s: choice(game.actions)\n",
        "              for s in game.states if not game.is_final(s)}\n",
        "\n",
        "\n",
        "    while True:\n",
        "\n",
        "        while True:\n",
        "            delta = 0\n",
        "            for s in game.states:\n",
        "                if game.is_final(s):\n",
        "                    continue\n",
        "                v_old = v[s]\n",
        "\n",
        "                v[s] = sum(\n",
        "                    p * (r + gamma * v[s_next])\n",
        "                    for (s_next, p, r) in game.effects(s, policy[s])\n",
        "                )\n",
        "                delta = max(delta, abs(v[s] - v_old))\n",
        "            if delta < max_delta:\n",
        "                break\n",
        "\n",
        "\n",
        "        policy_stable = True\n",
        "        for s in game.states:\n",
        "            if game.is_final(s):\n",
        "                continue\n",
        "            old_action = policy[s]\n",
        "\n",
        "            policy[s] = max(\n",
        "                game.actions,\n",
        "                key=lambda a: sum(\n",
        "                    p * (r + gamma * v[s_next])\n",
        "                    for (s_next, p, r) in game.effects(s, a)\n",
        "                )\n",
        "            )\n",
        "            if old_action != policy[s]:\n",
        "                policy_stable = False\n",
        "\n",
        "        if policy_stable:\n",
        "            break\n",
        "\n",
        "\n",
        "    return policy, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjf9uR5dZWw3"
      },
      "source": [
        "### Cerința 2\n",
        "Implementați funcția **value_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8eBq7CUZWw3"
      },
      "outputs": [],
      "source": [
        "def value_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    v = {s: 0 for s in game.states}\n",
        "    while True:\n",
        "        delta = 0\n",
        "\n",
        "        for s in game.states:\n",
        "            if game.is_final(s):\n",
        "                continue\n",
        "            v_old = v[s]\n",
        "\n",
        "            v[s] = max(\n",
        "                sum(p * (r + gamma * v[s_next])\n",
        "                    for (s_next, p, r) in game.effects(s, a))\n",
        "                for a in game.actions\n",
        "            )\n",
        "            delta = max(delta, abs(v[s] - v_old))\n",
        "\n",
        "        if delta < max_delta:\n",
        "            break\n",
        "\n",
        "\n",
        "    policy = {}\n",
        "    for s in game.states:\n",
        "        if game.is_final(s):\n",
        "            continue\n",
        "\n",
        "        policy[s] = max(\n",
        "            game.actions,\n",
        "            key=lambda a: sum(\n",
        "                p * (r + gamma * v[s_next])\n",
        "                for (s_next, p, r) in game.effects(s, a)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return policy, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6CoJAktMV_I"
      },
      "source": [
        "## Evaluare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDueFUXSMUwL",
        "outputId": "0dd8dea1-1de9-4dcf-802b-bb565bfd0708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP_NAME: simple\n",
            "Policy iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      |  0.23 |  0.31 |  0.41 |  0.54 |  0.71 |  0.93 |       |      \n",
            "      |  0.18 |  0.23 |       |       |       |  0.73 |  0.93 |      \n",
            "      |  0.14 |  0.17 |  0.13 |  0.09 |       |  0.54 |  0.70 |      \n",
            "      |  0.11 |  0.12 |  0.10 |  0.08 |  0.11 |  0.41 |  0.52 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→→B┃\n",
            "┃↑↑╺━╸↑↑┃\n",
            "┃↑↑←←A→↑┃\n",
            "┃↑↑←→↓→↑┃\n",
            "┗━━━━━━━┛\n",
            "Value iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      |  0.23 |  0.31 |  0.41 |  0.54 |  0.71 |  0.93 |       |      \n",
            "      |  0.18 |  0.23 |       |       |       |  0.73 |  0.93 |      \n",
            "      |  0.14 |  0.17 |  0.13 |  0.09 |       |  0.54 |  0.70 |      \n",
            "      |  0.11 |  0.12 |  0.10 |  0.08 |  0.11 |  0.41 |  0.52 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→→B┃\n",
            "┃↑↑╺━╸↑↑┃\n",
            "┃↑↑←←A→↑┃\n",
            "┃↑↑←→↓→↑┃\n",
            "┗━━━━━━━┛\n",
            "MAP_NAME: complex\n",
            "Policy iteration:\n",
            "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "      |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |  0.00 |  0.00 |       |       |       |       |       |      \n",
            "      |       |  0.95 |  0.73 |  0.55 |  0.42 |  0.31 |       |       |       |       |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |      \n",
            "      |       |       |       |       |       |  0.24 |       |       |       |       |       |       |       |       |       |       |  0.01 |      \n",
            "      |       |       |       |       |       |  0.18 |  0.14 |  0.10 |  0.08 |  0.06 |  0.05 |  0.03 |  0.03 |  0.02 |  0.02 |  0.01 |  0.01 |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━━━━━┓\n",
            "┃↑→→→→→→→→→↓┗┓\n",
            "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
            "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
            "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
            "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
            "┗┻┻┻┻┻━━━━━━━━━━━━┛\n",
            "Value iteration:\n",
            "      |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "      |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |       |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |  0.00 |  0.00 |       |       |       |       |       |      \n",
            "      |       |  0.95 |  0.73 |  0.55 |  0.42 |  0.31 |       |       |       |       |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |      \n",
            "      |       |       |       |       |       |  0.24 |       |       |       |       |       |       |       |       |       |       |  0.01 |      \n",
            "      |       |       |       |       |       |  0.18 |  0.14 |  0.10 |  0.08 |  0.06 |  0.05 |  0.03 |  0.03 |  0.02 |  0.02 |  0.01 |  0.01 |      \n",
            "      |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━━━━━┓\n",
            "┃↑→→→→→→→→→↓┗┓\n",
            "┃A╺━━━━┳┳┳┓↓↓┗━━━━┓\n",
            "┃B←←←←←┣╋╋┫→→→→→→↓┃\n",
            "┣┳┳┳┳┓↑┗┻┻┻━━━━━╸↓┃\n",
            "┣╋╋╋╋┫↑←←←←←←←←←←←┃\n",
            "┗┻┻┻┻┻━━━━━━━━━━━━┛\n",
            "MAP_NAME: be_careful\n",
            "Policy iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      | -4.23 | -3.97 | -3.61 | -3.18 | -2.61 | -1.86 |       |      \n",
            "      | -4.40 | -4.23 |       |       |       |  0.39 |       |      \n",
            "      | -4.53 | -4.41 | -4.31 | -4.41 |       | -0.73 |  0.59 |      \n",
            "      | -4.47 | -4.30 | -4.06 | -3.74 | -3.27 | -1.73 | -0.83 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→↓B┃\n",
            "┃↑↑╺━╸→C┃\n",
            "┃↑↑↓←A→↑┃\n",
            "┃→→→→→→↑┃\n",
            "┗━━━━━━━┛\n",
            "Value iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      | -4.23 | -3.97 | -3.61 | -3.18 | -2.61 | -1.86 |       |      \n",
            "      | -4.40 | -4.23 |       |       |       |  0.39 |       |      \n",
            "      | -4.53 | -4.41 | -4.31 | -4.41 |       | -0.73 |  0.59 |      \n",
            "      | -4.47 | -4.30 | -4.06 | -3.74 | -3.27 | -1.73 | -0.83 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→↓B┃\n",
            "┃↑↑╺━╸→C┃\n",
            "┃↑↑↓←A→↑┃\n",
            "┃→→→→→→↑┃\n",
            "┗━━━━━━━┛\n",
            "MAP_NAME: suffer\n",
            "Policy iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      | -1.70 | -1.43 | -1.06 | -0.60 | -0.01 |  0.77 |       |      \n",
            "      | -1.87 | -1.70 |       |       |       |  0.06 |  0.77 |      \n",
            "      | -1.90 | -1.71 | -1.45 | -1.10 |       | -0.52 | -0.06 |      \n",
            "      | -1.99 | -1.83 | -1.64 | -1.40 | -1.09 | -0.97 | -0.67 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→→B┃\n",
            "┃↑↑╺━╸↑↑┃\n",
            "┃→→→→A↑↑┃\n",
            "┃→→→→↑↑↑┃\n",
            "┗━━━━━━━┛\n",
            "Value iteration:\n",
            "      |       |       |       |       |       |       |       |      \n",
            "      | -1.70 | -1.43 | -1.06 | -0.60 | -0.01 |  0.77 |       |      \n",
            "      | -1.87 | -1.70 |       |       |       |  0.06 |  0.77 |      \n",
            "      | -1.90 | -1.71 | -1.45 | -1.10 |       | -0.52 | -0.06 |      \n",
            "      | -1.99 | -1.83 | -1.64 | -1.40 | -1.09 | -0.97 | -0.67 |      \n",
            "      |       |       |       |       |       |       |       |      \n",
            "┏━━━━━━━┓\n",
            "┃→→→→→→B┃\n",
            "┃↑↑╺━╸↑↑┃\n",
            "┃→→→→A↑↑┃\n",
            "┃→→→→↑↑↑┃\n",
            "┗━━━━━━━┛\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "\n",
        "for MAP_NAME in ['simple', 'complex', 'be_careful', 'suffer']:\n",
        "    print(\"MAP_NAME:\", MAP_NAME)\n",
        "\n",
        "    game = Maze(MAP_NAME)\n",
        "\n",
        "    print(\"Policy iteration:\")\n",
        "    policy, v = policy_iteration(game)\n",
        "    game.print_values(v)\n",
        "    game.print_policy(policy)\n",
        "\n",
        "    print(\"Value iteration:\")\n",
        "    policy, v = value_iteration(game)\n",
        "    game.print_values(v)\n",
        "    game.print_policy(policy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}